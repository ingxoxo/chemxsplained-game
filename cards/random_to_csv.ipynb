{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rawdatacsv=\"raw-word-data.csv\"\n",
    "shuffledcsv=\"shuffled_out_new.csv\"\n",
    "shuffledxls=\"shuffled_out_new.xls\"\n",
    "shuffledxls_pair_merge=\"shuffled_out_new_pair_merge.xls\"  # <---- new data set to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#instead of going through all n words and then shuffling - which results in n cards. \n",
    "# Rather treat the words as a bag of words. Once word is removed it is removed \n",
    "\n",
    "import csv\n",
    "import random\n",
    "import time\n",
    "import pandas\n",
    "import numpy as np\n",
    "df = pandas.read_csv(rawdatacsv)\n",
    "uniq = df.Concepts.unique()\n",
    "\n",
    "np.random.shuffle(uniq)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# is uniq divisible by the card size (4). if not pad with randoms from the first\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_unique(data, duplicates=None):\n",
    "    \"\"\" Returns a random string from data that is not in the list of duplicates\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    data : np.array or list\n",
    "        data is the list of data to pull from\n",
    "    duplicates : list, optional \n",
    "        duplicates is what the random output must not match\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    choice\n",
    "        a string\n",
    "    \n",
    "    Edgecase? horrible case where duplicated contains more data than data and this will endlessly loop - I shoudn't hit that edge case\n",
    "    \"\"\"\n",
    "    choice=random.choice(data)\n",
    "    if duplicates:\n",
    "        if choice in duplicates:\n",
    "            choice=random_unique(data,duplicates)\n",
    "    return choice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_data(data, card_size):\n",
    "    \"\"\" Based on the card size will pad the input data so that all rows are full. \n",
    "    e.g. 10 words and 4 words per card means 2 words padding and 12 words returned.\n",
    "    if mod is zero we're good\n",
    "    else if mod 1 pick a random  and check not in last slice. add it. \n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    data : np.array or list\n",
    "        data is the list of data to pull from\n",
    "    card_size : int \n",
    "        how many words per card.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    padded_data\n",
    "        a np.array or list with original data + random data needs to pad\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    mod = len(data)%card_size\n",
    "    if mod == 0:\n",
    "        return data\n",
    "    else:\n",
    "        # pick n random not in the last part of the data\n",
    "        dataslice = data[0:len(data)-mod-1]\n",
    "        new_data=[]\n",
    "        for i in range(0,card_size-mod):\n",
    "            new_data.append(random_unique(dataslice, new_data))\n",
    "        padded_data = np.append(data,new_data)\n",
    "        return padded_data\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shuffle, pad, repeat by until max, drop dups and return\n",
    "def generate_cards(data,card_size,max_loop, column_names=['word1', 'word2', 'word3', 'word4']):\n",
    "    \"\"\" Generate a set of data for creating cards in MS Word mail merge.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    data : np.array or list\n",
    "        data is the list of data to pull from\n",
    "    card_size : int \n",
    "        how many words per card.\n",
    "    max_loop : int\n",
    "        how many times to loop over the data sets and create more random word combinations\n",
    "    column_names : list\n",
    "        the names of columns - these are column heading for the dataframe and needed later for mailmerge\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    dataframe\n",
    "        a dataframe with card_size columns of shuffled words labelled as per column_names. dup rows removed.\n",
    "    \n",
    "    \"\"\"\n",
    "    list_of_datasets = []\n",
    "    np.random.shuffle(data)\n",
    "    data_set = pad_data(data,card_size)\n",
    "    for i in range(0,max_loop):\n",
    "        random.seed(random.randint(0,1000000000)) # get a new random seed for each shuffle\n",
    "        np.random.shuffle(data) # shuffle data each time to create a new view of the dataset\n",
    "        list_of_datasets.append(pad_data(data,card_size))\n",
    "    data_set = np.concatenate(list_of_datasets)\n",
    "    reshapedata=data_set.reshape((int(len(data_set)/card_size)), card_size)\n",
    "    df = pandas.DataFrame(reshapedata, columns=column_names)\n",
    "    return df.drop_duplicates()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fdf = generate_cards(uniq,4,4)\n",
    "fdf = fdf.rename_axis('index')\n",
    "fdf[0:100].to_excel(shuffledxls)\n",
    "fdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate as if 2 words per card and then combine, ensures words are found in both the discussion and drawing parts of the card\n",
    "one_df = generate_cards(uniq,2,2,column_names=['word1', 'word2'])\n",
    "two_df = generate_cards(uniq,2,2,column_names=['word3', 'word4'])\n",
    "\n",
    "merged_df = one_df.merge(two_df, left_index=True, right_index=True)\n",
    "\n",
    "merged_df = merged_df.rename_axis('index')\n",
    "merged_df[0:100].to_excel(shuffledxls_pair_merge)\n",
    "#len(pad_data(uniq,4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(merged_df[0:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    \n",
    "# noting a poor performance issue - where some words are repeated too many times. Actually most words are seen 4 times. Some are seen only 3 and some seen 5 times. \n",
    "# can create better stats but this is OK for now. \n",
    "# the main issue is words that appear 4 times in the same spot and only in drawing or only discussing.\n",
    "# using a different random seed seems to help but still the issue.\n",
    "\n",
    "# consider running this as if on 2 cards and then combine. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check stats when using a 2 card merge\n",
    "firsthundred = merged_df[0:100]\n",
    "for key in uniq:\n",
    "    w1=list(firsthundred.word1).count(key)\n",
    "    w2=list(firsthundred.word2).count(key)\n",
    "    w3=list(firsthundred.word3).count(key)\n",
    "    w4=list(firsthundred.word4).count(key)\n",
    "    print(key,w1,w2,w3,w4,w1+w2+w3+w4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check stats when using 4 words per card\n",
    "firsthundred = fdf[0:100]\n",
    "for key in uniq:\n",
    "    w1=list(firsthundred.word1).count(key)\n",
    "    w2=list(firsthundred.word2).count(key)\n",
    "    w3=list(firsthundred.word3).count(key)\n",
    "    w4=list(firsthundred.word4).count(key)\n",
    "    print(key,w1,w2,w3,w4,w1+w2+w3+w4)\n",
    "    \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
