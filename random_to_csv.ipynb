{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rawdatacsv=\"raw-word-data.csv\"\n",
    "shuffledcsv=\"shuffled_out_new.csv\"\n",
    "shuffledxls=\"shuffled_out_new.xls\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#instead of going through all n words and then shuffling - which results in n cards. \n",
    "# Rather treat the words as a bag of words. Once word is removed it is removed \n",
    "\n",
    "import csv\n",
    "import random\n",
    "import time\n",
    "import pandas\n",
    "import numpy as np\n",
    "df = pandas.read_csv(rawdatacsv)\n",
    "uniq = df.Concepts.unique()\n",
    "#df.Concepts.duplicated()\n",
    "#print(random.choice(df.Concepts))\n",
    "\n",
    "\n",
    "# while not empty pull words? \n",
    "# or shuffle in place with pandas. \n",
    "\n",
    "np.random.shuffle(uniq)\n",
    "#uniq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# is uniq divisible by the card size (4). if not pad with randoms from the first\n",
    "#for i in uniq:\n",
    "#    print(i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(uniq)%4\n",
    "# mod = np.append(uniq,'example')\n",
    "# #print(mod)\n",
    "# print(len(mod))\n",
    "# len(mod)%4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_unique(data, duplicates=None):\n",
    "    # data is the list of data to pull from\n",
    "    # duplicates is what the random output must not match\n",
    "    # horrible case where duplicated contains more data than data and this will endlessly loop - I shoudn't hit that edge case\n",
    "    choice=random.choice(data)\n",
    "    if duplicates:\n",
    "        if choice in duplicates:\n",
    "            choice=random_unique(data,duplicates)\n",
    "    return choice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_data(data, card_size):\n",
    "    # based on the card size will pad the input data so that all rows are full. \n",
    "    # e.g. 10 words and 4 words per card means 2 words padding and 12 words returned.\n",
    "    mod = len(data)%card_size\n",
    "    if mod == 0:\n",
    "        return data\n",
    "    else:\n",
    "        # pick n random not in the last part of the data\n",
    "        dataslice = data[0:len(data)-mod-1]\n",
    "        new_data=[]\n",
    "        for i in range(0,card_size-mod):\n",
    "            new_data.append(random_unique(dataslice, new_data))\n",
    "        padded_data = np.append(data,new_data)\n",
    "        return padded_data\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shuffle, pad, repeat by until max, drop dups and return\n",
    "def generate_cards(data,card_size,max_loop, column_names=['word1', 'word2', 'word3', 'word4']):\n",
    "    list_of_datasets = []\n",
    "    np.random.shuffle(data)\n",
    "    data_set = pad_data(data,card_size)\n",
    "    for i in range(0,max_loop):\n",
    "        np.random.shuffle(data)\n",
    "        list_of_datasets.append(pad_data(data,card_size))\n",
    "    data_set = np.concatenate(list_of_datasets)\n",
    "    reshapedata=data_set.reshape((int(len(data_set)/4)), card_size)\n",
    "    df = pandas.DataFrame(reshapedata, columns=column_names)\n",
    "    return df.drop_duplicates()\n",
    "#pad_data(uniq,4)\n",
    "#len(uniq)%4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.random.shuffle(uniq)\n",
    "# list_of_datasets = []\n",
    "# for i in range(0,4):\n",
    "#     np.random.shuffle(uniq)\n",
    "#     datai = pad_data(uniq,4)\n",
    "#     list_of_datasets.append(datai)\n",
    "# data_set = np.concatenate(list_of_datasets)\n",
    "# reshapedata=data_set.reshape((int(len(data_set)/4)), 4)\n",
    "# df2 = pandas.DataFrame(reshapedata, columns=['word1', 'word2', 'word3', 'word4'])\n",
    "# print(data_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fdf = generate_cards(uniq,4,4)\n",
    "fdf = fdf.rename_axis('index')\n",
    "fdf[0:100].to_excel(shuffledxls)\n",
    "#len(pad_data(uniq,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# come up with something reasonable\n",
    "# if mod is zero we're good\n",
    "# if mod 1 pick a random and check not in last 3 (cardsize-1) of the total size\n",
    "# if mod 2 pick a random and check not in last 3 (cardsize-2) of the total size\n",
    "# pull out the last slice for comparison purposes\n",
    "# for i in 0... mod\n",
    "# pick a random and check not in slice. add it. \n",
    "#print(random.choice(df.Concepts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # reshape the example\n",
    "# cardsize=4\n",
    "# reshaped=mod.reshape((int(len(mod)/4)), cardsize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshaped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mod_def = pandas.DataFrame(reshaped, columns=['word1', 'word2', 'word3', 'word4'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mod_def"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list(reshaped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a = np.array(['Metallic', 'Miscible', 'Freezing', 'Enthalpy'], dtype=object)\n",
    "# b = np.array(['Ion-dipole', 'Ion-Dipole', 'Cohesive forces', 'example'],\n",
    "#        dtype=object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set(list(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #np.append(mod_def, mod_def)\n",
    "# reshaped_append =np.append(reshaped,reshaped)\n",
    "# len(reshaped_append)\n",
    "# reshaped_twice=reshaped_append.reshape((int(len(reshaped_append)/4)), cardsize)\n",
    "# extended_test = pandas.DataFrame(reshaped_twice, columns=['word1', 'word2', 'word3', 'word4'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extended_test.drop_duplicates()\n",
    "# can create a few different runs and drop duplicates and choose first 100. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
